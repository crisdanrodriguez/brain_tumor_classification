{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcfed401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from scipy.stats import mode, kurtosis, skew, entropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Features Extraction Function\n",
    "\"\"\"\n",
    "# Get an image and returns first and second order features of the pixels array \n",
    "def get_image_features(image_path):\n",
    "    # Load the image and converts it into a 2-dimensional numpy array with the pixels values\n",
    "    image = io.imread(image_path, as_gray = True) * 255\n",
    "    # Resize image to 512 x 512\n",
    "    image = resize(image, (512, 512))\n",
    "    # Converts the float values of the 2-dimensional pixels array into uint8\n",
    "    image = image.astype(np.uint8)\n",
    "    \n",
    "    # Calculate the mean, variance and standard deviation of the 2-dimensional pixels array with numpy functions\n",
    "    mean = np.mean(image)\n",
    "    variance = np.var(image)\n",
    "    std = np.std(image)\n",
    "    \n",
    "    # Converts the 2-dimensional pixels array into 1-dimensional\n",
    "    image_1da = image.flatten()\n",
    "    \n",
    "    # Calculate the skewness, kurtosis and entropy of the 1-dimensional array with scipy.stats functions\n",
    "    skewness = skew(image_1da)\n",
    "    kurtos = kurtosis(image_1da)\n",
    "    entro = entropy(image_1da)\n",
    "\n",
    "    # Calculate the grey-level-co-ocurrence matrix with skimage functions\n",
    "    # The pixel pair distance offset used is 1\n",
    "    # The pixel pair angles used are 0, pi/4, pi/2 and 3pi/4\n",
    "    GLCM = greycomatrix(image, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "\n",
    "    # Calculate texture properties of the grey-level-co-ocurrence matrix \n",
    "    contrast = greycoprops(GLCM, 'contrast')[0, 0]\n",
    "    dissimilarity = greycoprops(GLCM, 'dissimilarity')[0, 0]\n",
    "    homogeneity = greycoprops(GLCM, 'homogeneity')[0, 0]\n",
    "    asm = greycoprops(GLCM, 'ASM')[0, 0]\n",
    "    energy = greycoprops(GLCM, 'energy')[0, 0]\n",
    "    correlation = greycoprops(GLCM, 'correlation')[0, 0]\n",
    "    \n",
    "    # Returns all the features values of the image\n",
    "    return mean, variance, std, skewness, kurtos, entro, contrast, dissimilarity, homogeneity, asm, energy, correlation\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "K-Nearest Neighbors Algorithm Functions\n",
    "\"\"\"\n",
    "# Gets two points and calculate the euclidean distance between them\n",
    "def euclidean_distance(p1, p2):\n",
    "    ed = np.sqrt(np.sum((p1 - p2) ** 2))\n",
    "    return ed\n",
    "\n",
    "# Function to predict the class with knn model\n",
    "def knn_predict(x_train, y_train, x_input, n_neighbors):\n",
    "    # List to store the predictions\n",
    "    predictions = []\n",
    "     \n",
    "    # Loop through the datapoints to be classified\n",
    "    for i in x_input:   \n",
    "        # List to store the distances\n",
    "        distances = []\n",
    "         \n",
    "        # Loop through each training data\n",
    "        for j in range(len(x_train)): \n",
    "            # Calculate the euclidean distance\n",
    "            ed = euclidean_distance(np.array(x_train[j, :]), i) \n",
    "            \n",
    "            # Add the calculated euclidean distance to the list\n",
    "            distances.append(ed) \n",
    "            \n",
    "        # Convert the list into a numpy array\n",
    "        distances = np.array(distances) \n",
    "         \n",
    "        # Sort the array while preserving the index\n",
    "        # Keep the first n_neighbors datapoints\n",
    "        dist_sorted = np.argsort(distances)[:n_neighbors] \n",
    "         \n",
    "        # Labels of the n_neighbors datapoints from above\n",
    "        labels = y_train[dist_sorted]\n",
    "         \n",
    "        # Determine the majority label in labels\n",
    "        label = mode(labels).mode[0] \n",
    "        predictions.append(label)\n",
    "        \n",
    "    # Returns a list with the predictions\n",
    "    return predictions\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Decision Trees Algorithm Functions\n",
    "\"\"\"\n",
    "def entropy(y):\n",
    "    hist = np.bincount(y)\n",
    "    ps = hist / len(y)\n",
    "    return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(\n",
    "        self, feature=None, threshold=None, left=None, right=None, *, value=None\n",
    "    ):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, n_feats=None):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_feats = n_feats\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        # stopping criteria\n",
    "        if (\n",
    "            depth >= self.max_depth\n",
    "            or n_labels == 1\n",
    "            or n_samples < self.min_samples_split\n",
    "        ):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        feat_idxs = np.random.choice(n_features, self.n_feats, replace=False)\n",
    "\n",
    "        # greedily select the best split according to information gain\n",
    "        best_feat, best_thresh = self._best_criteria(X, y, feat_idxs)\n",
    "\n",
    "        # grow the children that result from the split\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
    "        return Node(best_feat, best_thresh, left, right)\n",
    "\n",
    "    def _best_criteria(self, X, y, feat_idxs):\n",
    "        best_gain = -1\n",
    "        split_idx, split_thresh = None, None\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(y, X_column, threshold)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_thresh = threshold\n",
    "\n",
    "        return split_idx, split_thresh\n",
    "\n",
    "    def _information_gain(self, y, X_column, split_thresh):\n",
    "        # parent loss\n",
    "        parent_entropy = entropy(y)\n",
    "\n",
    "        # generate split\n",
    "        left_idxs, right_idxs = self._split(X_column, split_thresh)\n",
    "\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        # compute the weighted avg. of the loss for the children\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = entropy(y[left_idxs]), entropy(y[right_idxs])\n",
    "        child_entropy = (n_l / n) * e_l + (n_r / n) * e_r\n",
    "\n",
    "        # information gain is difference in loss before vs. after split\n",
    "        ig = parent_entropy - child_entropy\n",
    "        return ig\n",
    "\n",
    "    def _split(self, X_column, split_thresh):\n",
    "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        return most_common\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Naive Bayes Algorithm Functions\n",
    "\"\"\"\n",
    "\n",
    "def prior(df, class_column):\n",
    "    classes = sorted(list(df[class_column].unique()))\n",
    "    priors = []\n",
    "    \n",
    "    for i in classes:\n",
    "        priors.append(len(df[df[class_column] == i]) / len(df))\n",
    "    return priors\n",
    "\n",
    "def likelihood_gaussian(df, feat_name, feat_val, class_column, label):\n",
    "    feat = list(df.columns)\n",
    "    df = df[df[class_column] == label]\n",
    "    mean, std = df[feat_name].mean(), df[feat_name].std()\n",
    "    p_x_given_y = (1 / (np.sqrt(2 * np.pi) * std)) * np.exp(-((feat_val - mean) ** 2 / (2 * std ** 2)))\n",
    "    return p_x_given_y\n",
    "\n",
    "def nb_predict(df, x_input, class_column):\n",
    "    features = list(df.columns)[:-1]\n",
    "    \n",
    "    priors = prior(df, class_column)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for x in x_input:\n",
    "        labels = sorted(list(df[class_column].unique()))\n",
    "        likelihood = [1] * len(labels)\n",
    "        for j in range(len(labels)):\n",
    "            for i in range(len(features)):\n",
    "                likelihood[j] *= likelihood_gaussian(df, features[i], x[i], class_column, labels[j])\n",
    "                \n",
    "        post_prob = [1] * len(labels)\n",
    "        for j in range(len(labels)):\n",
    "            post_prob[j] = likelihood[j] * priors[j]\n",
    "            \n",
    "        predictions.append(np.argmax(post_prob))\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "515615ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "      <th>std</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>dissimilarity</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>asm</th>\n",
       "      <th>energy</th>\n",
       "      <th>correlation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.957241</td>\n",
       "      <td>1534.028907</td>\n",
       "      <td>39.166681</td>\n",
       "      <td>0.591976</td>\n",
       "      <td>-0.146808</td>\n",
       "      <td>12.115296</td>\n",
       "      <td>54.121755</td>\n",
       "      <td>3.947006</td>\n",
       "      <td>0.408638</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.074824</td>\n",
       "      <td>0.982349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.239227</td>\n",
       "      <td>1702.933157</td>\n",
       "      <td>41.266611</td>\n",
       "      <td>1.525444</td>\n",
       "      <td>3.256895</td>\n",
       "      <td>12.212518</td>\n",
       "      <td>39.458877</td>\n",
       "      <td>2.382121</td>\n",
       "      <td>0.663735</td>\n",
       "      <td>0.071248</td>\n",
       "      <td>0.266923</td>\n",
       "      <td>0.988422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.551712</td>\n",
       "      <td>1860.386608</td>\n",
       "      <td>43.132199</td>\n",
       "      <td>1.174871</td>\n",
       "      <td>1.526766</td>\n",
       "      <td>11.981298</td>\n",
       "      <td>42.525494</td>\n",
       "      <td>3.121216</td>\n",
       "      <td>0.510266</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>0.109885</td>\n",
       "      <td>0.988572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.573677</td>\n",
       "      <td>2225.436749</td>\n",
       "      <td>47.174535</td>\n",
       "      <td>0.879047</td>\n",
       "      <td>0.867972</td>\n",
       "      <td>12.257411</td>\n",
       "      <td>36.775501</td>\n",
       "      <td>3.006803</td>\n",
       "      <td>0.535195</td>\n",
       "      <td>0.026063</td>\n",
       "      <td>0.161442</td>\n",
       "      <td>0.991737</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.876183</td>\n",
       "      <td>2688.290875</td>\n",
       "      <td>51.848731</td>\n",
       "      <td>0.695864</td>\n",
       "      <td>-0.464646</td>\n",
       "      <td>11.865826</td>\n",
       "      <td>34.988839</td>\n",
       "      <td>2.842435</td>\n",
       "      <td>0.565111</td>\n",
       "      <td>0.036918</td>\n",
       "      <td>0.192142</td>\n",
       "      <td>0.993493</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>43.240494</td>\n",
       "      <td>1728.160768</td>\n",
       "      <td>41.571153</td>\n",
       "      <td>1.032431</td>\n",
       "      <td>1.358818</td>\n",
       "      <td>11.996204</td>\n",
       "      <td>35.655661</td>\n",
       "      <td>2.656304</td>\n",
       "      <td>0.561187</td>\n",
       "      <td>0.019953</td>\n",
       "      <td>0.141256</td>\n",
       "      <td>0.989684</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>31.026756</td>\n",
       "      <td>2054.392251</td>\n",
       "      <td>45.325404</td>\n",
       "      <td>1.474903</td>\n",
       "      <td>1.355120</td>\n",
       "      <td>11.522565</td>\n",
       "      <td>42.386963</td>\n",
       "      <td>2.596273</td>\n",
       "      <td>0.676621</td>\n",
       "      <td>0.109545</td>\n",
       "      <td>0.330977</td>\n",
       "      <td>0.989695</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>43.290009</td>\n",
       "      <td>1392.145868</td>\n",
       "      <td>37.311471</td>\n",
       "      <td>1.077291</td>\n",
       "      <td>2.438517</td>\n",
       "      <td>12.079829</td>\n",
       "      <td>42.669891</td>\n",
       "      <td>2.780008</td>\n",
       "      <td>0.536012</td>\n",
       "      <td>0.009523</td>\n",
       "      <td>0.097585</td>\n",
       "      <td>0.984667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>46.065979</td>\n",
       "      <td>2176.462016</td>\n",
       "      <td>46.652567</td>\n",
       "      <td>0.798026</td>\n",
       "      <td>-0.141716</td>\n",
       "      <td>11.928128</td>\n",
       "      <td>28.031548</td>\n",
       "      <td>2.543993</td>\n",
       "      <td>0.570965</td>\n",
       "      <td>0.021920</td>\n",
       "      <td>0.148054</td>\n",
       "      <td>0.993561</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>44.859615</td>\n",
       "      <td>1942.205066</td>\n",
       "      <td>44.070456</td>\n",
       "      <td>1.026604</td>\n",
       "      <td>0.870684</td>\n",
       "      <td>11.979179</td>\n",
       "      <td>37.397734</td>\n",
       "      <td>2.829799</td>\n",
       "      <td>0.534900</td>\n",
       "      <td>0.017912</td>\n",
       "      <td>0.133835</td>\n",
       "      <td>0.990373</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3206 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean     variance        std  skewness  kurtosis    entropy  \\\n",
       "0     47.957241  1534.028907  39.166681  0.591976 -0.146808  12.115296   \n",
       "1     53.239227  1702.933157  41.266611  1.525444  3.256895  12.212518   \n",
       "2     43.551712  1860.386608  43.132199  1.174871  1.526766  11.981298   \n",
       "3     70.573677  2225.436749  47.174535  0.879047  0.867972  12.257411   \n",
       "4     49.876183  2688.290875  51.848731  0.695864 -0.464646  11.865826   \n",
       "...         ...          ...        ...       ...       ...        ...   \n",
       "3201  43.240494  1728.160768  41.571153  1.032431  1.358818  11.996204   \n",
       "3202  31.026756  2054.392251  45.325404  1.474903  1.355120  11.522565   \n",
       "3203  43.290009  1392.145868  37.311471  1.077291  2.438517  12.079829   \n",
       "3204  46.065979  2176.462016  46.652567  0.798026 -0.141716  11.928128   \n",
       "3205  44.859615  1942.205066  44.070456  1.026604  0.870684  11.979179   \n",
       "\n",
       "       contrast  dissimilarity  homogeneity       asm    energy  correlation  \\\n",
       "0     54.121755       3.947006     0.408638  0.005599  0.074824     0.982349   \n",
       "1     39.458877       2.382121     0.663735  0.071248  0.266923     0.988422   \n",
       "2     42.525494       3.121216     0.510266  0.012075  0.109885     0.988572   \n",
       "3     36.775501       3.006803     0.535195  0.026063  0.161442     0.991737   \n",
       "4     34.988839       2.842435     0.565111  0.036918  0.192142     0.993493   \n",
       "...         ...            ...          ...       ...       ...          ...   \n",
       "3201  35.655661       2.656304     0.561187  0.019953  0.141256     0.989684   \n",
       "3202  42.386963       2.596273     0.676621  0.109545  0.330977     0.989695   \n",
       "3203  42.669891       2.780008     0.536012  0.009523  0.097585     0.984667   \n",
       "3204  28.031548       2.543993     0.570965  0.021920  0.148054     0.993561   \n",
       "3205  37.397734       2.829799     0.534900  0.017912  0.133835     0.990373   \n",
       "\n",
       "      label  \n",
       "0         3  \n",
       "1         0  \n",
       "2         1  \n",
       "3         2  \n",
       "4         2  \n",
       "...     ...  \n",
       "3201      2  \n",
       "3202      2  \n",
       "3203      1  \n",
       "3204      2  \n",
       "3205      2  \n",
       "\n",
       "[3206 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/brain_tumor_dataset.csv', index_col = 0)\n",
    "\n",
    "dataset = dataset.drop(['image_name', 'label_name'], axis = 1)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "555b2c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.5829\n",
      "NB: 0.5565\n",
      "DT: 0.7321\n",
      "Stacking: 0.6698\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "acc_knn = []\n",
    "acc_nb = []\n",
    "acc_dts = []\n",
    "acc_s = []\n",
    "for i in range(4):\n",
    "    train, test = train_test_split(dataset, test_size = 0.2)\n",
    "\n",
    "    x_train = train.iloc[:, :-1].values\n",
    "    y_train = train.iloc[:, -1].values\n",
    "\n",
    "    x_test = test.iloc[:, :-1].values\n",
    "    y_test = test.iloc[:, -1].values\n",
    "    \n",
    "    knn_test = knn_predict(x_train, y_train, x_test, n_neighbors = 5)\n",
    "    nb_test = nb_predict(train, x_test, class_column = 'label')\n",
    "    \n",
    "    dts_test = dt.predict(x_test)\n",
    "    \n",
    "    stacking_test = pd.DataFrame(columns = ('knn', 'dts', 'nb', 'true_label'))\n",
    "    stacking_test['knn'] = knn_test\n",
    "    stacking_test['dts'] = dts_test\n",
    "    stacking_test['nb'] = nb_test\n",
    "    stacking_test['true_label'] = y_test\n",
    "    \n",
    "    x_test_s = stacking_test.iloc[:, :-1].values\n",
    "    \n",
    "    s_test = knn_predict(x_train_mm, y_train_mm, x_test_s, n_neighbors = 5)\n",
    "\n",
    "    acc_knn.append(accuracy_score(y_test, knn_test))\n",
    "    acc_nb.append(accuracy_score(y_test, nb_test))\n",
    "    acc_dts.append(accuracy_score(y_test, dts_test))\n",
    "    acc_s.append(accuracy_score(y_test, s_test))\n",
    "    \n",
    "print('KNN: %.4f' % (np.mean(acc_knn)))\n",
    "print('NB: %.4f' % (np.mean(acc_nb)))\n",
    "print('DT: %.4f' % (np.mean(acc_dts)))\n",
    "print('Stacking: %.4f' % (np.mean(acc_s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525c6bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size = 0.2)\n",
    "\n",
    "x_train = train.iloc[:, :-1].values\n",
    "y_train = train.iloc[:, -1].values\n",
    "\n",
    "x_test = test.iloc[:, :-1].values\n",
    "y_test = test.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1225be",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a26690",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_preds = knn_predict(x_train, y_train, x_train, n_neighbors = 5)\n",
    "knn_tests = knn_predict(x_train, y_train, x_test, n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b9d9c7",
   "metadata": {},
   "source": [
    "# NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c010a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_preds = nb_predict(train, x_train, class_column = 'label')\n",
    "nb_tests = nb_predict(train, x_test, class_column = 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e6e56a",
   "metadata": {},
   "source": [
    "# DTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a3df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree(max_depth = 7)\n",
    "dt.fit(x_train, y_train)\n",
    "dts_preds = dt.predict(x_train)\n",
    "dts_tests = dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2424d2",
   "metadata": {},
   "source": [
    "# Meta model df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e45f6e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "      <th>dts</th>\n",
       "      <th>nb</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   knn  dts  nb  true_label\n",
       "0    1    1   1           1\n",
       "1    3    3   3           3\n",
       "2    3    3   3           3\n",
       "3    3    0   0           0\n",
       "4    1    1   1           1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model_df = pd.DataFrame(columns = ('knn', 'dts', 'nb', 'true_label'))\n",
    "\n",
    "meta_model_df['knn'] = knn_preds\n",
    "meta_model_df['dts'] = dts_preds\n",
    "meta_model_df['nb'] = nb_preds\n",
    "meta_model_df['true_label'] = y_train\n",
    "\n",
    "meta_model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fef2c197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "      <th>dts</th>\n",
       "      <th>nb</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>642 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     knn  dts  nb  true_label\n",
       "0      1    1   1           1\n",
       "1      1    2   1           2\n",
       "2      2    0   3           2\n",
       "3      3    3   3           3\n",
       "4      1    2   1           2\n",
       "..   ...  ...  ..         ...\n",
       "637    1    1   1           1\n",
       "638    2    2   2           1\n",
       "639    2    2   2           1\n",
       "640    1    3   0           3\n",
       "641    3    1   1           3\n",
       "\n",
       "[642 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_test = pd.DataFrame(columns = ('knn', 'dts', 'nb', 'true_label'))\n",
    "\n",
    "stacking_test['knn'] = knn_tests\n",
    "stacking_test['dts'] = dts_tests\n",
    "stacking_test['nb'] = nb_tests\n",
    "stacking_test['true_label'] = y_test\n",
    "\n",
    "stacking_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26400c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       ...,\n",
       "       [1, 2, 1],\n",
       "       [3, 3, 3],\n",
       "       [2, 2, 2]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_s = stacking_test.iloc[:, :-1].values\n",
    "y_test_s = stacking_test.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f899677",
   "metadata": {},
   "source": [
    "# KNN Meta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c919d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mm, test_mm = train_test_split(meta_model_df, test_size = 0.2)\n",
    "\n",
    "x_train_mm = train_mm.iloc[:, :-1].values\n",
    "y_train_mm = train_mm.iloc[:, -1].values\n",
    "\n",
    "x_test_mm = test_mm.iloc[:, :-1].values\n",
    "y_test_mm = test_mm.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3064e37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7485380116959064\n",
      "0.6401869158878505\n"
     ]
    }
   ],
   "source": [
    "mm_test = knn_predict(x_train_mm, y_train_mm, x_test_mm, n_neighbors = 5)\n",
    "mm_preds = knn_predict(x_train_mm, y_train_mm, x_test_s, n_neighbors = 5)\n",
    "\n",
    "print(accuracy_score(y_test_mm, mm_test))\n",
    "print(accuracy_score(y_test_s, mm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/Testing/glioma_tumor/gt_83.jpg'\n",
    "\n",
    "features = np.array([get_image_features(path)])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba465618",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_x = knn_predict(x_train, y_train, features, n_neighbors = 5)\n",
    "dts_x = dt.predict(features)\n",
    "nb_x = nb_predict(train, features, class_column = 'label')\n",
    "\n",
    "news = np.array([[knn_x[0], dts_x[0], nb_x[0]]])\n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddeaa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predict(x_train2, y_train2, news, n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806a0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7dec68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ac87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eabc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "tree_clf = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 7) \n",
    "tree_clf.fit(x_train, y_train)\n",
    "tree.plot_tree(tree_clf)\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f188040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# filter warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def accuracy(k, X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    compute accuracy of the classification based on k values \n",
    "    '''\n",
    "    # instantiate learning model and fit data\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)    \n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # predict the response\n",
    "    pred = knn.predict(X_test)\n",
    "\n",
    "    # evaluate and return  accuracy\n",
    "    return accuracy_score(y_test, pred)\n",
    "\n",
    "def classify_and_plot(X, y):\n",
    "    ''' \n",
    "    split data, fit, classify, plot and evaluate results \n",
    "    '''\n",
    "    # split data into training and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 41)\n",
    "\n",
    "    # init vars\n",
    "    n_neighbors = 5\n",
    "    h           = .02  # step size in the mesh\n",
    "\n",
    "    # Create color maps\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAAAFF'])\n",
    "    cmap_bold  = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "    rcParams['figure.figsize'] = 5, 5\n",
    "    for weights in ['uniform', 'distance']:\n",
    "        # we create an instance of Neighbours Classifier and fit the data.\n",
    "        clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                             np.arange(y_min, y_max, h))\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        fig = plt.figure()\n",
    "        plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "        # Plot also the training points, x-axis = 'Glucose', y-axis = \"BMI\"\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)   \n",
    "        plt.xlim(xx.min(), xx.max())\n",
    "        plt.ylim(yy.min(), yy.max())\n",
    "        plt.title(\"0/1 outcome classification (k = %i, weights = '%s')\" % (n_neighbors, weights))\n",
    "        plt.show()\n",
    "        fig.savefig(weights +'.png')\n",
    "\n",
    "        # evaluate\n",
    "        y_expected  = y_test\n",
    "        y_predicted = clf.predict(X_test)\n",
    "\n",
    "        # print results\n",
    "        print('----------------------------------------------------------------------')\n",
    "        print('Classification report')\n",
    "        print('----------------------------------------------------------------------')\n",
    "        print('\\n', classification_report(y_expected, y_predicted))\n",
    "        print('----------------------------------------------------------------------')\n",
    "        print('Accuracy = %5s' % round(accuracy(n_neighbors, X_train, y_train, X_test, y_test), 3))\n",
    "        print('----------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "# load your data \n",
    "data  = pd.read_csv('data/brain_tumor_dataset.csv')\n",
    "dataset = data.drop(['image_name', 'label_name'], axis = 1)\n",
    "\n",
    "names = list(dataset.columns)\n",
    "\n",
    "# we only take the best two features and prepare them for the KNN classifier\n",
    "rows_nbr = dataset.shape[0]\n",
    "X_prime  = np.array(dataset.iloc[:rows_nbr, [1,5]])\n",
    "X        = X_prime # preprocessing.scale(X_prime)\n",
    "y        = np.array(dataset.iloc[:rows_nbr, 8])\n",
    "\n",
    "# classify, evaluate and plot results\n",
    "classify_and_plot(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1620df9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
